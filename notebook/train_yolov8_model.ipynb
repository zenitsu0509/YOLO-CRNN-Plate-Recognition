{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# For YOLO model\n!pip install ultralytics -q\n\n# For OCR model and data handling\n!pip install tensorflow huggingface_hub -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T10:16:23.707785Z","iopub.execute_input":"2025-07-26T10:16:23.707997Z","iopub.status.idle":"2025-07-26T10:17:53.795077Z","shell.execute_reply.started":"2025-07-26T10:16:23.707969Z","shell.execute_reply":"2025-07-26T10:17:53.794035Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport cv2\nimport yaml\nimport random\nimport tarfile\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nfrom ultralytics import YOLO\nimport easyocr # Replaced keras_ocr\n\nfrom huggingface_hub import hf_hub_download\n\nprint(\"Imports successful!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T10:17:53.797295Z","iopub.execute_input":"2025-07-26T10:17:53.797593Z","iopub.status.idle":"2025-07-26T10:18:01.882268Z","shell.execute_reply.started":"2025-07-26T10:17:53.797556Z","shell.execute_reply":"2025-07-26T10:18:01.881633Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nImports successful!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def download_and_extract_dataset(repo_id, archive_filename, expected_internal_folder):\n    \"\"\"\n    Downloads a .tar.gz file from Hugging Face Hub, extracts it, and returns the path\n    to the main data folder inside.\n    \n    Args:\n        repo_id (str): The Hugging Face repository ID (e.g., \"username/repo-name\").\n        archive_filename (str): The name of the .tar.gz file in the repo.\n        expected_internal_folder (str): The name of the top-level folder inside the archive.\n        \n    Returns:\n        str: The local path to the extracted data folder.\n    \"\"\"\n    # Define where to download and extract\n    download_dir = \"/content/downloads\"\n    extract_dir = \"/content/extracted_datasets\"\n    os.makedirs(download_dir, exist_ok=True)\n    os.makedirs(extract_dir, exist_ok=True)\n    \n    print(f\"--- Processing {repo_id} ---\")\n    \n    # 1. Download the file\n    print(f\"Downloading {archive_filename}...\")\n    downloaded_path = hf_hub_download(\n        repo_id=repo_id,\n        filename=archive_filename,\n        repo_type=\"dataset\",\n        local_dir=download_dir\n    )\n    print(f\"Downloaded to: {downloaded_path}\")\n    \n    # 2. Extract the archive\n    print(f\"Extracting to {extract_dir}...\")\n    with tarfile.open(downloaded_path, \"r:gz\") as tar:\n        tar.extractall(path=extract_dir)\n    print(\"Extraction complete.\")\n    \n    # 3. Return the path to the actual data folder\n    dataset_path = os.path.join(extract_dir, expected_internal_folder)\n    \n    if not os.path.exists(dataset_path):\n        raise FileNotFoundError(f\"Expected folder '{dataset_path}' not found after extraction.\")\n        \n    print(f\"âœ“ Dataset ready at: {dataset_path}\\n\")\n    return dataset_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T10:18:05.176258Z","iopub.execute_input":"2025-07-26T10:18:05.176532Z","iopub.status.idle":"2025-07-26T10:18:05.182862Z","shell.execute_reply.started":"2025-07-26T10:18:05.176510Z","shell.execute_reply":"2025-07-26T10:18:05.181997Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# !!! IMPORTANT: Replace with your actual username !!!\nHF_USERNAME = \"zenitsu09\"\nYOLO_REPO_ID = f\"{HF_USERNAME}/ccpd-yolo-detection\"\nYOLO_ARCHIVE_NAME = \"yolo_dataset.tar.gz\"\nYOLO_INTERNAL_FOLDER = \"ccpd_yolo\" # This was the root folder you archived\n\nyolo_dataset_path = download_and_extract_dataset(\n    repo_id=YOLO_REPO_ID,\n    archive_filename=YOLO_ARCHIVE_NAME,\n    expected_internal_folder=YOLO_INTERNAL_FOLDER\n)\n\n# The path to the training configuration file\nyolo_yaml_path = os.path.join(yolo_dataset_path, 'ccpd_yolo.yaml')\nprint(f\"Path to YOLO config file: {yolo_yaml_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T10:18:08.656266Z","iopub.execute_input":"2025-07-26T10:18:08.656545Z","iopub.status.idle":"2025-07-26T10:22:47.694449Z","shell.execute_reply.started":"2025-07-26T10:18:08.656525Z","shell.execute_reply":"2025-07-26T10:22:47.693762Z"}},"outputs":[{"name":"stdout","text":"--- Processing zenitsu09/ccpd-yolo-detection ---\nDownloading yolo_dataset.tar.gz...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"yolo_dataset.tar.gz:   0%|          | 0.00/5.23G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3245076343ef4de294952801ddfa5791"}},"metadata":{}},{"name":"stdout","text":"Downloaded to: /content/downloads/yolo_dataset.tar.gz\nExtracting to /content/extracted_datasets...\nExtraction complete.\nâœ“ Dataset ready at: /content/extracted_datasets/ccpd_yolo\n\nPath to YOLO config file: /content/extracted_datasets/ccpd_yolo/ccpd_yolo.yaml\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import yaml\n\n# Path to the YOLO dataset configuration file\nyolo_yaml_path = '/content/extracted_datasets/ccpd_yolo/ccpd_yolo.yaml'\n\ntry:\n    # Read the existing YAML content\n    with open(yolo_yaml_path, 'r') as f:\n        yolo_config = yaml.safe_load(f)\n\n    # Update the 'path' to the correct extraction directory\n    correct_dataset_path = '/content/extracted_datasets/ccpd_yolo'\n    yolo_config['path'] = correct_dataset_path\n\n    # Write the modified content back to the YAML file\n    with open(yolo_yaml_path, 'w') as f:\n        yaml.dump(yolo_config, f)\n\n    print(f\"Successfully updated the 'path' in {yolo_yaml_path} to: {correct_dataset_path}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file {yolo_yaml_path} was not found.\")\nexcept Exception as e:\n    print(f\"An error occurred while modifying the file: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T10:23:18.597881Z","iopub.execute_input":"2025-07-26T10:23:18.598129Z","iopub.status.idle":"2025-07-26T10:23:18.605982Z","shell.execute_reply.started":"2025-07-26T10:23:18.598111Z","shell.execute_reply":"2025-07-26T10:23:18.605170Z"}},"outputs":[{"name":"stdout","text":"Successfully updated the 'path' in /content/extracted_datasets/ccpd_yolo/ccpd_yolo.yaml to: /content/extracted_datasets/ccpd_yolo\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Load a pre-trained YOLOv8n model\nmodel = YOLO('yolov8n.pt')\n\nprint(\"Starting YOLOv8 training...\")\n# Train the model\nresults = model.train(\n    data=yolo_yaml_path,\n    epochs=3,\n    imgsz=640,\n    project='yolo_training',\n    name='lp_detector_from_zip' # Changed name to avoid conflicts\n)\nprint(\"YOLOv8 training complete!\")\n\n# Path to the best model\nyolo_best_model_path = 'yolo_training/lp_detector_from_zip/weights/best.pt'\nprint(f\"Best YOLO model saved at: {yolo_best_model_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T10:44:19.373101Z","iopub.execute_input":"2025-07-26T10:44:19.373898Z"}},"outputs":[{"name":"stdout","text":"Starting YOLOv8 training...\nUltralytics 8.3.169 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/extracted_datasets/ccpd_yolo/ccpd_yolo.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=lp_detector_from_zip3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolo_training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolo_training/lp_detector_from_zip3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1225.5Â±582.7 MB/s, size: 71.0 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/extracted_datasets/ccpd_yolo/labels/train.cache... 78767 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78767/78767 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 478.1Â±271.8 MB/s, size: 95.6 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /content/extracted_datasets/ccpd_yolo/labels/val.cache... 9846 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9846/9846 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to yolo_training/lp_detector_from_zip3/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1myolo_training/lp_detector_from_zip3\u001b[0m\nStarting training for 3 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        1/3      3.53G      1.003      0.675      1.026         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4923/4923 [14:32<00:00,  5.65it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308/308 [00:44<00:00,  6.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       9846       9846      0.994      0.997      0.994      0.768\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        2/3      3.64G     0.9441     0.4387      1.021         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4923/4923 [14:05<00:00,  5.82it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308/308 [00:44<00:00,  6.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       9846       9846      0.995      0.998      0.994       0.79\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        3/3      3.64G     0.8953      0.393      1.002         28        640:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3667/4923 [10:16<03:21,  6.23it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/working/yolo_training/lp_detector_from_zip","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}